---
title: "Importing, Tidying, and Tranforming Data"
output: html_document
date: "2024-01-26"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Series On: Data Wrangling and Visualization in R

## Session 1: Importing Data, Data Wrangling, and Tidy Data

![No data science without data!](images/import.png)

### Objectives of today's session

1.  Learn how to import raw data in R.

2.  Creat tidy dataset from raw data using `tidyr`.

3.  Use `dplyr` package for data transformation.

## Plan

1.  Read excel file, show arguments how they work
2.  Read tab-delimited file, show arguments how they work
3.  Read comma-sep files, show arguments how they work
4.  For other types of files, json, xml look for function in R
5.  **Exercise: Import a sample CSV file and an Excel file into R from directory**
6.  Introduction to **`dplyr`** packages.
7.  Common data manipulation tasks: filtering, selecting, mutating, summarizing.
8.  Grouping data and performing operations on groups.
9.  Joining data from different sources.
10. Handling missing data.
11. **Exercise: ask students to do some basic operations on sample dataset from prev exercise**

Tidy data is **a standard way of mapping the meaning of a dataset to its structure**.

```{r}
library(dplyr)
```

------------------------------------------------------------------------

## R is a simple calculator

| Operator | Description                 |
|----------|-----------------------------|
| \+       | Addition                    |
| \-       | Subtraction                 |
| \*       | Multiplication              |
| /        | Division                    |
| \^       | Exponentiation (Power)      |
| %%       | Modulus (Remainder)         |
| %/%      | Integer Division (Quotient) |

```{r}
398 + 783

600 / 5

45 * 45
```

### [**Exercise:1**]{style="color:coral"}

[1. Try doing following calculation using math operators]{style="color:coral;"}

$$
\frac{1+5^{1/2}} {2}
$$

```{r}
# Your code here

```

[2. Find modulus of 5 divided by 2]{style="color:coral"}

```{r}
# Your code here

```

------------------------------------------------------------------------

## R script

create a new script file (File \> New File \> R Script)

```{r}
## Copy this code in the R script

# Assigning numbers to variables
a <- 5
b <- 3

# Addition
sum_result <- a + b

# Subtraction
diff_result <- a - b

# Print the results
print("Results of Basic Math Operations:")
print(paste("Sum: ", sum_result))
print(paste("Difference: ", diff_result))
```

## Data types

```{r}
num_variable <- 42.5
class(num_variable)
```

```{r}
char_variable = "Welcome to the DS club"
class(char_variable)
```

```{r}
logic_variable = TRUE
class(logic_variable)
```

```{r}
num_variable == 42.5
num_variable >= 50
class(num_variable == 42.5)
```

## R Functions

3 Key Properties of an R function.

-   functions have a name and they are case sensetive

-   following the name they have a pair of ()

-   inside (), function take 0 or more arguments

```{r}
summ_two_numbers <- function(a=3, b=6){
  return(a+b)
}

summ_two_numbers()
summ_two_numbers(5, 19)
```

### [**Exercise:2**]{style="color:coral"}

[Complete this code to return square of 9]{style="color:coral"}

```{r eval=FALSE, include=TRUE}
# Your code here
squared_num <- function(x){
   squared = ___
   return(___)
 }
 
 squared_num(9)
```

------------------------------------------------------------------------

# R vectors

```{r}
nums_vector = c(2, 5, 10, 60)

nums_vector[3]

nums_vector[2:3]

nums_vector[nums_vector > 9]
```

[Exercise: create a vector of odd numbers till 10 and return numbers greater than 5]{style="color:coral"}

```{r}
# Your code here

```

## Read data

Need help looking at the many arguments of read.table you can define? It's easy.

Type this on the cosole: `?read.table`

Don't know what your file looks like? No issue. We can check by reading the file line by line. This works even when the file size in GBs and we don't have a software to open the file on our operating system.

```{r}
# Specify the path to your file
file_path1 <- "Datasets/file_1_to_read.txt"

# Read the first few lines
readLines(file_path1, n = 5)
```

*Note: You can not create an R dataframe and perform data analysis by reading a file line by line.*

```{r}
df1 = read.table(file_path1, sep="\t", header = TRUE)
```

To check if your data was properly read

```{r}
df1
```

### [**Exercise 3**]{style="color:coral"}

```{r}
# Specify the path to your file
file_path2 <- "Datasets/file_2_to_read.txt"
```

[1. Try figuring out what are the best arguments to read the second file]{style="color:coral;"}

```{r}
# Hint: Read the first few lines

```

[2. Now use read.table function to create the df2]{style="color:coral;"}

```{r eval=FALSE, include=TRUE}
# Complete the code
df2 = read.table(file_path2, , )

df2
```

## Using libraries

All packages are installed in this environment. If you will use RStudio on your machine you will have to install packages before you can load them.

```{r}
library(readr)
read_csv("Datasets/file_3_to_read.csv", col_select = c(1:4))
```

```{r}
read_csv("Datasets/file_3_to_read.csv", col_select = c(4:9))
```

```{r}
library(readxl)
read_xlsx("Datasets/file_4_to_read.xlsx", sheet = 'Sheet1')
```

------------------------------------------------------------------------

# Split cells with `tidyr` package

[Exercise: load `tidyr` package]{style="color:red"}

```{r}
#Your Code Here
```

```{r}
# Let's create sample dataframe and look at some tidyr functions to merge and split data

splicing_data <- data.frame(
  Event_ID = c('ENSG171863_RI', 
               'ENSG168356_SE', 
               'ENSG160185_SE', 
               'ENSG243960_A5',
               'ENSG197291_A3'),
  PSI_value_1 = as.character(c('0.', '0.', '0.', '0.', '1.')),
  PSI_value_2 = as.character(c(1,2,3,4,0)),
  Group = c("A", "B", "B", "A", "A"), 
  Some_Attribute = c('NA', 5, "NA", 9, 'NA')
)

splicing_data
```

```{r}
new_splicing_data = tidyr::unite(splicing_data, PSI_value_1, PSI_value_2, col="PSI_value", sep="", remove=TRUE)
new_splicing_data

# return new dataframe with new defined column
# also we can remove old columns or retain them
# you could play with "sep" and "col" arguments
```

```{r}
# tidyr::separate same as tidyr::separate_wider_delim
tidyr::separate(splicing_data, Event_ID, sep="_", into=c('ID', 'Splicing event'), remove=TRUE)
```

[Exercise: work with another dataset, unite and separate this dataset]{style="color:red"}

1.  Import the data into R.

*Hint: Its a Tab Separated file*

```{r eval=FALSE, include=TRUE}
# Complete the code here
path <- "Datasets/gff_file.txt"
df3 <- read.table(path, )
```

2.  Select column `c(1,3,4,5, and 9)`

*Hint: Check Base R cheat sheet*

```{r eval=FALSE, include=TRUE}
# Your the code here
```

2.  Separate column 9 by `sep=";"` and remove the last two columns

*Hint: Its the same as selecting the first 5 columns*

```{r eval=FALSE, include=TRUE}
# Complete the code here
tidyr::select(df3, )
```

# Reshape data


```{r}
# First of all, let's create sample dataframe and then reshape it
table2 <- data.frame(
  country = c('A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'C', 'C', 'C', 'C'),
  year = c(1999, 1999, 2000, 2000, 1999, 1999, 2000, 2000, 1999, 1999, 2000, 2000),
  type = c('cases', 'pop', 'cases', 'pop', 'cases', 'pop', 'cases', 'pop', 'cases', 'pop', 'cases', 'pop'),
  count = c('0.7K', '19M', '2K', '20M', '37K', '172M', '80K', '174M', '212K', '1T', '213K', '1T')
)

table2
```

```{r}
# Let's reshape it
tidyr::pivot_wider(table2, names_from = type, values_from = count)
```

[**I think we don't need exercise here**]{style="color:red"}

# Dplyr package

-   *Select* certain columns of data.

-   *Filter* your data to select specific rows.

-   *Arrange* the rows of your data into an order.

-   *Mutate* your data frame to contain new columns.

-   *Summarise* chunks of you data in some way.

Letâ€™s look at how those work.

# joining, transforming and summarizing

### Return back to our splicing data, and join it to another dataframe with new Attribute2, but new dataframe has information only for 4 Events

What to do??? ---\> left and right joins

```{r}
new_splicing_data$PSI_value = as.numeric(new_splicing_data$PSI_value)
new_splicing_data
```

```{r}
tmp_df = data.frame(
  Event_ID = c('ENSG171863_RI', 'ENSG168356_SE', 'ENSG160185_SE', 'ENSG243960_A5'),
  Attribute2 = c(43, 54, 72, 26))
tmp_df
```

### dplyr::left_join

```{r}
dplyr::left_join(new_splicing_data, tmp_df, by="Event_ID")
```

### dplyr::right_join

```{r}
dplyr::right_join(new_splicing_data, tmp_df, by="Event_ID")
```

### dplyr::select

```{r}
# Select needed columns 
new_splicing_data %>% select(Event_ID)
```

### dplyr::mutate()

```{r}
# Transform data in dataframe
new_splicing_data %>% mutate(new_PSI_value = 10*PSI_value)
```

### dplyr::filter()

```{r}
new_splicing_data %>% filter(PSI_value > 0.2)
```

### dplyr::group_by() & dplyr::summarise()

```{r}
new_splicing_data %>% 
  group_by(Group) %>%
  summarise(
    mean_value = mean(PSI_value)
  )
```

[**Exercise: for below splicing data**]{style="color:red"}

[1. **Select Events with PSI_value below 0.5**]{style="color:red"}

[2. **For found Events, find sum and mean values for each groups where these Events are**]{style="color:red"}

```{r}
new_splicing_data

# Your code here
# ...
```

# Write data

```{r}
write.csv(new_splicing_data, 'new_splicing_data.csv')
 
# readr::write_excel_csv()
```

## Revolutionize coding in R with the pipe function `%>%`
```{r ,eval=FALSE}
library(dplyr)
```


```{r eval=FALSE, include=FALSE}
read.table(path, sep="\t") %>%
  dplyr::select(c(1:5,9)) %>%
  tidyr::separate(6,sep=";",into = c("Gene","X","Y")) %>%
  dplyr::select(c(1:6))
```